import os
from typing import Optional, List, Dict, Any
from dotenv import load_dotenv

# Cargar variables de entorno
load_dotenv()

try:
    from openai import OpenAI
except Exception:
    OpenAI = None

client = None
if OpenAI and os.getenv("OPENAI_API_KEY"):
    try:
        client = OpenAI()
    except Exception as e:
        print(f"Warning: No se pudo inicializar el cliente de OpenAI: {e}")
        client = None

def ask_openai(prompt: str) -> str:
    """
    FunciÃ³n bÃ¡sica que mantiene compatibilidad con el cÃ³digo existente
    """
    if client is None:
        return generate_smart_response(prompt)
    try:
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role":"system","content":"Eres un asistente de soporte amable y breve."},
                      {"role":"user","content": prompt}],
            temperature=0.2,
            max_tokens=300
        )
        return resp.choices[0].message.content
    except Exception as e:
        return f"(OpenAI error) {e}"

def advanced_chat_completion(
    messages: List[Dict[str, str]], 
    model: str = "gpt-4o-mini",
    temperature: float = 0.7,
    max_tokens: int = 500,
    stream: bool = False
) -> Dict[str, Any]:
    """
    FunciÃ³n avanzada para completar conversaciones con mÃ¡s control
    """
    if client is None:
        return {
            "success": False,
            "error": "OpenAI client not initialized",
            "response": "ðŸ¤– (Simulado) Entiendo tu consulta. OpenAI no estÃ¡ configurado."
        }
    
    try:
        response = client.chat.completions.create(
            model=model,
            messages=messages,
            temperature=temperature,
            max_tokens=max_tokens,
            stream=stream
        )
        
        if stream:
            return {
                "success": True,
                "stream": response
            }
        else:
            return {
                "success": True,
                "response": response.choices[0].message.content,
                "usage": {
                    "prompt_tokens": response.usage.prompt_tokens,
                    "completion_tokens": response.usage.completion_tokens,
                    "total_tokens": response.usage.total_tokens
                }
            }
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "response": f"Lo siento, hubo un error procesando tu consulta: {str(e)}"
        }

def generate_smart_response(prompt: str, db=None, rag_context: str = "") -> str:
    """
    Genera una respuesta inteligente usando OpenAI con contexto de productos
    """
    if client is None:
        return generate_fallback_response(prompt)
    
    try:
        # Obtener productos de la base de datos para contexto
        products_context = ""
        if db:
            try:
                from ..models import Product
                products = db.query(Product).filter(Product.active == True).limit(6).all()
                if products:
                    products_context = "\n\nProductos disponibles en Asistente Tienda:\n"
                    for i, product in enumerate(products, 1):
                        products_context += f"{i}. {product.title} - Q{product.price:.2f} - {product.description}\n"
            except Exception as e:
                print(f"Error obteniendo productos: {e}")
        
        # Construir mensaje del sistema mejorado para OpenAI
        system_message = f"""Eres una consultora de moda experta y elegante para Asistente Tienda, una tienda online de alta calidad. 
        Tu objetivo es ayudar a los clientes de manera sofisticada, profesional y encantadora.
        
        ESTILO DE COMUNICACIÃ“N:
        - Tono elegante, sofisticado y amigable
        - Usa emojis de manera sutil y profesional
        - Lenguaje refinado pero accesible
        - Respuestas estructuradas y visualmente atractivas
        - Siempre menciona "Asistente Tienda" cuando sea apropiado
        - MÃ¡ximo 200 palabras por respuesta
        
        INFORMACIÃ“N DE LA TIENDA:
        - Somos Asistente Tienda, una tienda online especializada en moda
        - Ofrecemos productos de alta calidad con precios competitivos
        - Tenemos envÃ­os a domicilio y atenciÃ³n personalizada
        - Nuestro horario de atenciÃ³n es de lunes a viernes de 9:00 a 18:00
        - Los precios estÃ¡n en Quetzales (Q)
        
        {products_context}
        
        INSTRUCCIONES ESPECÃFICAS:
        - Si preguntan por productos, menciona los disponibles y sus precios
        - Si preguntan por envÃ­os, explica nuestras opciones de entrega
        - Si preguntan por horarios, menciona nuestro horario de atenciÃ³n
        - Siempre ofrece ayuda adicional y menciona que pueden hacer pedidos
        - Usa un tono profesional pero cÃ¡lido
        - MantÃ©n las respuestas concisas pero informativas
        - Responde siempre en espaÃ±ol"""
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_message},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=400
        )
        
        return response.choices[0].message.content
        
    except Exception as e:
        print(f"Error en OpenAI: {e}")
        return generate_fallback_response(prompt)

def generate_fallback_response(prompt: str) -> str:
    """
    Genera una respuesta de fallback cuando OpenAI no estÃ¡ disponible
    """
    prompt_lower = prompt.lower()
    
    # Respuestas bÃ¡sicas de fallback
    if any(word in prompt_lower for word in ['hola', 'buenos dÃ­as', 'buenas tardes', 'buenas noches', 'saludos']):
        return "Â¡Hola! ðŸ‘‹ Bienvenido a **Asistente Tienda**. Soy tu asistente virtual y estoy aquÃ­ para ayudarte. Â¿En quÃ© puedo asistirte hoy?"
    
    if any(word in prompt_lower for word in ['productos', 'producto', 'items', 'artÃ­culos']):
        return "ðŸ›ï¸ **Asistente Tienda** tiene una gran variedad de productos de moda disponibles. Â¿Hay algÃºn tipo de producto especÃ­fico que te interese?"
    
    if any(word in prompt_lower for word in ['precio', 'precios', 'costo', 'costos']):
        return "ðŸ’° **Asistente Tienda** ofrece precios muy competitivos. Â¿Hay algÃºn producto especÃ­fico del que te gustarÃ­a conocer el precio?"
    
    if any(word in prompt_lower for word in ['envÃ­o', 'envÃ­os', 'entrega', 'delivery']):
        return "ðŸšš **Asistente Tienda** ofrece envÃ­os a domicilio. Â¿Te gustarÃ­a saber mÃ¡s sobre nuestras opciones de envÃ­o?"
    
    # Respuesta genÃ©rica
    return f"ðŸ¤– Entiendo tu consulta sobre '{prompt[:50]}...'. Estoy aquÃ­ para ayudarte con informaciÃ³n sobre nuestros productos, precios, envÃ­os o cualquier otra consulta. Â¿PodrÃ­as ser mÃ¡s especÃ­fico sobre lo que necesitas?"

def generate_contextual_response(
    query: str,
    context: Dict[str, Any],
    conversation_history: List[Dict[str, str]] = None
) -> str:
    """
    Genera una respuesta contextualizada usando el sistema RAG avanzado
    """
    if client is None:
        # Usar respuesta inteligente con contexto de la base de datos
        rag_context = ""
        if context.get("document_context"):
            rag_context = context["document_context"]
        elif context.get("product_context"):
            rag_context = context["product_context"]
        
        return generate_smart_response(query, rag_context=rag_context)
    
    # Construir mensajes para el chat
    messages = []
    
    # Mensaje del sistema con personalidad mejorada para productos
    # Mensaje del sistema con personalidad elegante y sofisticada
    system_message = """Eres una consultora de moda experta y elegante para Asistente Tienda, una tienda online de alta calidad. 
    Tu objetivo es ayudar a los clientes de manera sofisticada, profesional y encantadora.
    
    ESTILO DE COMUNICACIÃ“N:
    - Tono elegante, sofisticado y amigable
    - Usa emojis de manera sutil y profesional
    - Lenguaje refinado pero accesible
    - Respuestas estructuradas y visualmente atractivas
    - MÃ¡ximo 200 palabras por respuesta
    
    CUANDO MUESTRES PRODUCTOS:
    - Presenta cada producto como una joya Ãºnica
    - Destaca caracterÃ­sticas especiales y beneficios
    - Usa descripciones evocativas y atractivas
    - NO incluyas enlaces tÃ©cnicos ni URLs
    - EnfÃ³cate en la experiencia del cliente
    - Sugiere combinaciones y estilos
    
    FORMATO ELEGANTE PARA PRODUCTOS:
    âœ¨ [Nombre del producto] - $[precio]
    ðŸ’Ž [DescripciÃ³n atractiva y beneficios]
    ðŸ›ï¸ [Sugerencia de uso o combinaciÃ³n]
    
    PERSONALIDAD:
    - Eres una consultora de moda experta y elegante
    - Te emocionas por ayudar a crear looks perfectos
    - Eres detallista pero no abrumadora
    - Mantienes un aire de sofisticaciÃ³n y profesionalismo
    - Siempre terminas con una invitaciÃ³n amigable para mÃ¡s ayuda
    
    EJEMPLOS DE FRASES ELEGANTES:
    - PermÃ­teme presentarte nuestros tesoros mÃ¡s preciados...
    - Este artÃ­culo es simplemente excepcional porque...
    - ImagÃ­nate luciendo este hermoso...
    - Â¿Te gustarÃ­a conocer mÃ¡s detalles sobre algÃºn producto en particular?"""
    
    messages.append({"role": "system", "content": system_message})
    
    # Agregar historial de conversaciÃ³n
    if conversation_history:
        for msg in conversation_history[-6:]:  # Ãšltimos 6 mensajes para contexto
            # Manejar tanto objetos como diccionarios
            if isinstance(msg, dict):
                role = "user" if msg.get("sender") == "user" else "assistant"
                content = msg.get("content", "")
            else:
                role = "user" if msg.sender == "user" else "assistant"
                content = msg.content
            messages.append({"role": role, "content": content})
    
    # Construir prompt contextual mejorado
    context_parts = []
    
    if context.get("product_context"):
        context_parts.append(f"INFORMACIÃ“N DE PRODUCTOS DISPONIBLES:\n{context['product_context']}")
    
    if context.get("document_context"):
        context_parts.append(f"INFORMACIÃ“N ADICIONAL:\n{context['document_context']}")
    
    if context.get("product_mentions"):
        context_parts.append(f"El cliente mencionÃ³ estos productos: {', '.join(context['product_mentions'])}")
    
    if context_parts:
        context_prompt = "\n\n".join(context_parts)
        messages.append({"role": "system", "content": f"CONTEXTO ACTUAL:\n{context_prompt}"})
    
    # Agregar la consulta del usuario
    messages.append({"role": "user", "content": query})
    
    # Generar respuesta
    result = advanced_chat_completion(
        messages=messages,
        model="gpt-4o-mini",
        temperature=0.8,  # Aumentar creatividad
        max_tokens=500    # Permitir respuestas mÃ¡s largas para productos
    )
    
    if result["success"]:
        return result["response"]
    else:
        return result["response"]  # Ya incluye mensaje de error amigable

def extract_product_recommendations(response: str) -> List[Dict[str, str]]:
    """
    Extrae recomendaciones de productos de la respuesta del LLM
    """
    # PatrÃ³n simple para detectar menciones de productos
    import re
    
    recommendations = []
    # Buscar patrones como "Producto X", "Te recomiendo Y", etc.
    patterns = [
        r'recomiendo\s+([^.!?]+)',
        r'te\s+sugiero\s+([^.!?]+)',
        r'producto[s]?\s+([^.!?]+)',
        r'item[s]?\s+([^.!?]+)'
    ]
    
    for pattern in patterns:
        matches = re.findall(pattern, response.lower())
        for match in matches:
            if len(match.strip()) > 3:
                recommendations.append({
                    "product": match.strip(),
                    "reason": "Recomendado por el asistente"
                })
    
    return recommendations
