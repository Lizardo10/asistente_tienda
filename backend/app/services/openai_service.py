import os
from typing import Optional, List, Dict, Any
from dotenv import load_dotenv

# Cargar variables de entorno
load_dotenv()

try:
    from openai import OpenAI
except Exception:
    OpenAI = None

client = None
if OpenAI and os.getenv("OPENAI_API_KEY"):
    try:
        client = OpenAI()
    except Exception as e:
        print(f"Warning: No se pudo inicializar el cliente de OpenAI: {e}")
        client = None

def ask_openai(prompt: str) -> str:
    """
    Funci√≥n b√°sica que mantiene compatibilidad con el c√≥digo existente
    """
    if client is None:
        return generate_smart_response(prompt)
    try:
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role":"system","content":"Eres un asistente de soporte amable y breve."},
                      {"role":"user","content": prompt}],
            temperature=0.2,
            max_tokens=300
        )
        return resp.choices[0].message.content
    except Exception as e:
        return f"(OpenAI error) {e}"

def advanced_chat_completion(
    messages: List[Dict[str, str]], 
    model: str = "gpt-4o-mini",
    temperature: float = 0.7,
    max_tokens: int = 500,
    stream: bool = False
) -> Dict[str, Any]:
    """
    Funci√≥n avanzada para completar conversaciones con m√°s control
    """
    if client is None:
        return {
            "success": False,
            "error": "OpenAI client not initialized",
            "response": "ü§ñ (Simulado) Entiendo tu consulta. OpenAI no est√° configurado."
        }
    
    try:
        response = client.chat.completions.create(
            model=model,
            messages=messages,
            temperature=temperature,
            max_tokens=max_tokens,
            stream=stream
        )
        
        if stream:
            return {
                "success": True,
                "stream": response
            }
        else:
            return {
                "success": True,
                "response": response.choices[0].message.content,
                "usage": {
                    "prompt_tokens": response.usage.prompt_tokens,
                    "completion_tokens": response.usage.completion_tokens,
                    "total_tokens": response.usage.total_tokens
                }
            }
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "response": f"Lo siento, hubo un error procesando tu consulta: {str(e)}"
        }

def generate_smart_response(prompt: str, db=None, rag_context: str = "") -> str:
    """
    Genera una respuesta inteligente usando la base de datos y RAG cuando OpenAI no est√° disponible
    """
    prompt_lower = prompt.lower()
    
    # Respuestas para saludos
    if any(word in prompt_lower for word in ['hola', 'buenos d√≠as', 'buenas tardes', 'buenas noches', 'saludos']):
        return "¬°Hola! üëã Bienvenido a nuestra tienda online. Soy tu asistente virtual y estoy aqu√≠ para ayudarte con cualquier consulta sobre nuestros productos, precios, env√≠os o cualquier otra informaci√≥n que necesites. ¬øEn qu√© puedo asistirte hoy?"
    
    # Respuestas sobre productos
    if any(word in prompt_lower for word in ['productos', 'producto', 'items', 'art√≠culos', 'qu√© tienen', 'cat√°logo']):
        if db:
            try:
                from ..models import Product
                products = db.query(Product).filter(Product.active == True).limit(5).all()
                if products:
                    response = "üì¶ Aqu√≠ tienes algunos de nuestros productos disponibles:\n\n"
                    for product in products:
                        response += f"‚Ä¢ **{product.title}** - ${product.price:.2f}\n"
                        if product.description:
                            response += f"  _{product.description[:80]}..._\n\n"
                    response += "¬øTe interesa alg√∫n producto en particular? Puedo darte m√°s detalles."
                    return response
            except Exception:
                pass
        return "üì¶ Tenemos una gran variedad de productos disponibles. ¬øHay alg√∫n tipo de producto espec√≠fico que te interese? Puedo ayudarte a encontrar lo que necesitas."
    
    # Respuestas sobre precios
    if any(word in prompt_lower for word in ['precio', 'precios', 'costo', 'costos', 'cu√°nto cuesta', 'valor']):
        if db:
            try:
                from ..models import Product
                products = db.query(Product).filter(Product.active == True).all()
                if products:
                    min_price = min(p.price for p in products)
                    max_price = max(p.price for p in products)
                    return f"üí∞ Nuestros precios son muy competitivos. Los productos van desde ${min_price:.2f} hasta ${max_price:.2f}. ¬øHay alg√∫n producto espec√≠fico del que te gustar√≠a conocer el precio exacto?"
            except Exception:
                pass
        return "üí∞ Nuestros precios son muy competitivos. Los productos van desde $45 hasta $200 aproximadamente. ¬øHay alg√∫n producto espec√≠fico del que te gustar√≠a conocer el precio exacto?"
    
    # Respuestas sobre compras/pedidos
    if any(word in prompt_lower for word in ['comprar', 'pedido', 'orden', 'c√≥mo compro', 'c√≥mo hago un pedido']):
        return "üõí ¬°Excelente! Para hacer un pedido es muy f√°cil:\n\n1. Navega por nuestros productos\n2. Selecciona los que te interesen\n3. Agr√©galos al carrito\n4. Procede al checkout\n5. Completa tus datos de env√≠o\n\n¬øNecesitas ayuda con alg√∫n paso espec√≠fico?"
    
    # Respuestas sobre env√≠os
    if any(word in prompt_lower for word in ['env√≠o', 'env√≠os', 'entrega', 'delivery', 'cu√°ndo llega']):
        return "üöö Ofrecemos env√≠os a toda la ciudad. Los tiempos de entrega son:\n\n‚Ä¢ Env√≠o est√°ndar: 2-3 d√≠as h√°biles\n‚Ä¢ Env√≠o express: 1 d√≠a h√°bil\n‚Ä¢ Env√≠o gratis en compras mayores a $100\n\n¬øTe gustar√≠a saber m√°s sobre nuestras opciones de env√≠o?"
    
    # Respuestas sobre ayuda/soporte
    if any(word in prompt_lower for word in ['ayuda', 'soporte', 'problema', 'issue', 'error']):
        return "üÜò ¬°Por supuesto! Estoy aqu√≠ para ayudarte. Puedo asistirte con:\n\n‚Ä¢ Informaci√≥n sobre productos\n‚Ä¢ Proceso de compra\n‚Ä¢ Consultas sobre env√≠os\n‚Ä¢ Resoluci√≥n de problemas\n\n¬øCu√°l es el problema espec√≠fico que necesitas resolver?"
    
    # Buscar productos espec√≠ficos mencionados
    if db:
        try:
            from ..models import Product
            products = db.query(Product).filter(Product.active == True).all()
            for product in products:
                if product.title.lower() in prompt_lower:
                    return f"üëï ¬°Perfecto! S√≠ tenemos **{product.title}** disponible por ${product.price:.2f}. {product.description[:100]}... ¬øTe interesa este producto o necesitas m√°s informaci√≥n?"
        except Exception:
            pass
    
    # Usar contexto RAG si est√° disponible
    if rag_context:
        return f"ü§ñ Bas√°ndome en la informaci√≥n disponible: {rag_context[:200]}... ¬øTe gustar√≠a que profundice en alg√∫n aspecto espec√≠fico?"
    
    # Respuesta gen√©rica inteligente
    return f"ü§ñ Entiendo tu consulta sobre '{prompt[:50]}...'. Estoy aqu√≠ para ayudarte con informaci√≥n sobre nuestros productos, precios, env√≠os o cualquier otra consulta. ¬øPodr√≠as ser m√°s espec√≠fico sobre lo que necesitas?"

def generate_contextual_response(
    query: str,
    context: Dict[str, Any],
    conversation_history: List[Dict[str, str]] = None
) -> str:
    """
    Genera una respuesta contextualizada usando el sistema RAG avanzado
    """
    if client is None:
        # Usar respuesta inteligente con contexto de la base de datos
        rag_context = ""
        if context.get("document_context"):
            rag_context = context["document_context"]
        elif context.get("product_context"):
            rag_context = context["product_context"]
        
        return generate_smart_response(query, rag_context=rag_context)
    
    # Construir mensajes para el chat
    messages = []
    
    # Mensaje del sistema con personalidad mejorada para productos
    # Mensaje del sistema con personalidad elegante y sofisticada
    system_message = """Eres una consultora de moda experta y elegante para una tienda online de alta calidad. 
    Tu objetivo es ayudar a los clientes de manera sofisticada, profesional y encantadora.
    
    ESTILO DE COMUNICACI√ìN:
    - Tono elegante, sofisticado y amigable
    - Usa emojis de manera sutil y profesional
    - Lenguaje refinado pero accesible
    - Respuestas estructuradas y visualmente atractivas
    - M√°ximo 200 palabras por respuesta
    
    CUANDO MUESTRES PRODUCTOS:
    - Presenta cada producto como una joya √∫nica
    - Destaca caracter√≠sticas especiales y beneficios
    - Usa descripciones evocativas y atractivas
    - NO incluyas enlaces t√©cnicos ni URLs
    - Enf√≥cate en la experiencia del cliente
    - Sugiere combinaciones y estilos
    
    FORMATO ELEGANTE PARA PRODUCTOS:
    ‚ú® [Nombre del producto] - $[precio]
    üíé [Descripci√≥n atractiva y beneficios]
    üõçÔ∏è [Sugerencia de uso o combinaci√≥n]
    
    PERSONALIDAD:
    - Eres una consultora de moda experta y elegante
    - Te emocionas por ayudar a crear looks perfectos
    - Eres detallista pero no abrumadora
    - Mantienes un aire de sofisticaci√≥n y profesionalismo
    - Siempre terminas con una invitaci√≥n amigable para m√°s ayuda
    
    EJEMPLOS DE FRASES ELEGANTES:
    - Perm√≠teme presentarte nuestros tesoros m√°s preciados...
    - Este art√≠culo es simplemente excepcional porque...
    - Imag√≠nate luciendo este hermoso...
    - ¬øTe gustar√≠a conocer m√°s detalles sobre alg√∫n producto en particular?"""
    
    messages.append({"role": "system", "content": system_message})
    
    # Agregar historial de conversaci√≥n
    if conversation_history:
        for msg in conversation_history[-6:]:  # √öltimos 6 mensajes para contexto
            # Manejar tanto objetos como diccionarios
            if isinstance(msg, dict):
                role = "user" if msg.get("sender") == "user" else "assistant"
                content = msg.get("content", "")
            else:
                role = "user" if msg.sender == "user" else "assistant"
                content = msg.content
            messages.append({"role": role, "content": content})
    
    # Construir prompt contextual mejorado
    context_parts = []
    
    if context.get("product_context"):
        context_parts.append(f"INFORMACI√ìN DE PRODUCTOS DISPONIBLES:\n{context['product_context']}")
    
    if context.get("document_context"):
        context_parts.append(f"INFORMACI√ìN ADICIONAL:\n{context['document_context']}")
    
    if context.get("product_mentions"):
        context_parts.append(f"El cliente mencion√≥ estos productos: {', '.join(context['product_mentions'])}")
    
    if context_parts:
        context_prompt = "\n\n".join(context_parts)
        messages.append({"role": "system", "content": f"CONTEXTO ACTUAL:\n{context_prompt}"})
    
    # Agregar la consulta del usuario
    messages.append({"role": "user", "content": query})
    
    # Generar respuesta
    result = advanced_chat_completion(
        messages=messages,
        model="gpt-4o-mini",
        temperature=0.8,  # Aumentar creatividad
        max_tokens=500    # Permitir respuestas m√°s largas para productos
    )
    
    if result["success"]:
        return result["response"]
    else:
        return result["response"]  # Ya incluye mensaje de error amigable

def extract_product_recommendations(response: str) -> List[Dict[str, str]]:
    """
    Extrae recomendaciones de productos de la respuesta del LLM
    """
    # Patr√≥n simple para detectar menciones de productos
    import re
    
    recommendations = []
    # Buscar patrones como "Producto X", "Te recomiendo Y", etc.
    patterns = [
        r'recomiendo\s+([^.!?]+)',
        r'te\s+sugiero\s+([^.!?]+)',
        r'producto[s]?\s+([^.!?]+)',
        r'item[s]?\s+([^.!?]+)'
    ]
    
    for pattern in patterns:
        matches = re.findall(pattern, response.lower())
        for match in matches:
            if len(match.strip()) > 3:
                recommendations.append({
                    "product": match.strip(),
                    "reason": "Recomendado por el asistente"
                })
    
    return recommendations
