import os
from typing import Optional, List, Dict, Any
from dotenv import load_dotenv

# Cargar variables de entorno
load_dotenv()

try:
    from openai import OpenAI
except Exception:
    OpenAI = None

client = None
if OpenAI and os.getenv("OPENAI_API_KEY"):
    try:
        client = OpenAI()
    except Exception as e:
        print(f"Warning: No se pudo inicializar el cliente de OpenAI: {e}")
        client = None

def ask_openai(prompt: str) -> str:
    """
    Funci√≥n b√°sica que mantiene compatibilidad con el c√≥digo existente
    """
    if client is None:
        return generate_smart_response(prompt)
    try:
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role":"system","content":"Eres un asistente de soporte amable y breve."},
                      {"role":"user","content": prompt}],
            temperature=0.2,
            max_tokens=300
        )
        return resp.choices[0].message.content
    except Exception as e:
        return f"(OpenAI error) {e}"

def advanced_chat_completion(
    messages: List[Dict[str, str]], 
    model: str = "gpt-4o-mini",
    temperature: float = 0.7,
    max_tokens: int = 500,
    stream: bool = False
) -> Dict[str, Any]:
    """
    Funci√≥n avanzada para completar conversaciones con m√°s control
    """
    if client is None:
        return {
            "success": False,
            "error": "OpenAI client not initialized",
            "response": "ü§ñ (Simulado) Entiendo tu consulta. OpenAI no est√° configurado."
        }
    
    try:
        response = client.chat.completions.create(
            model=model,
            messages=messages,
            temperature=temperature,
            max_tokens=max_tokens,
            stream=stream
        )
        
        if stream:
            return {
                "success": True,
                "stream": response
            }
        else:
            return {
                "success": True,
                "response": response.choices[0].message.content,
                "usage": {
                    "prompt_tokens": response.usage.prompt_tokens,
                    "completion_tokens": response.usage.completion_tokens,
                    "total_tokens": response.usage.total_tokens
                }
            }
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "response": f"Lo siento, hubo un error procesando tu consulta: {str(e)}"
        }

def generate_smart_response(prompt: str, db=None, rag_context: str = "") -> str:
    """
    Genera una respuesta inteligente usando OpenAI con contexto de productos
    """
    if client is None:
        return generate_fallback_response(prompt)
    
    try:
        # Obtener productos de la base de datos para contexto
        products_context = ""
        if db:
            try:
                from ..models import Product
                products = db.query(Product).filter(Product.active == True).limit(6).all()
                if products:
                    products_context = "\n\nProductos disponibles en Asistente Tienda:\n"
                    for i, product in enumerate(products, 1):
                        products_context += f"{i}. {product.title} - Q{product.price:.2f} - {product.description}\n"
            except Exception as e:
                print(f"Error obteniendo productos: {e}")
        
        # Construir mensaje del sistema mejorado para OpenAI
        system_message = f"""Eres una consultora de moda experta y elegante para Asistente Tienda, una tienda online de alta calidad. 
        Tu objetivo es ayudar a los clientes de manera sofisticada, profesional y encantadora.
        
        ESTILO DE COMUNICACI√ìN:
        - Tono elegante, sofisticado y amigable
        - Usa emojis de manera sutil y profesional
        - Lenguaje refinado pero accesible
        - Respuestas estructuradas y visualmente atractivas
        - Siempre menciona "Asistente Tienda" cuando sea apropiado
        - M√°ximo 200 palabras por respuesta
        
        INFORMACI√ìN DE LA TIENDA:
        - Somos Asistente Tienda, una tienda online especializada en moda
        - Ofrecemos productos de alta calidad con precios competitivos
        - Tenemos env√≠os a domicilio y atenci√≥n personalizada
        - Nuestro horario de atenci√≥n es de lunes a viernes de 9:00 a 18:00
        - Los precios est√°n en Quetzales (Q)
        
        {products_context}
        
        INSTRUCCIONES ESPEC√çFICAS:
        - Si preguntan por productos, menciona los disponibles y sus precios
        - Si preguntan por env√≠os, explica nuestras opciones de entrega
        - Si preguntan por horarios, menciona nuestro horario de atenci√≥n
        - Siempre ofrece ayuda adicional y menciona que pueden hacer pedidos
        - Usa un tono profesional pero c√°lido
        - Mant√©n las respuestas concisas pero informativas
        - Responde siempre en espa√±ol"""
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_message},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=400
        )
        
        return response.choices[0].message.content
        
    except Exception as e:
        print(f"Error en OpenAI: {e}")
        return generate_fallback_response(prompt)

def generate_fallback_response(prompt: str) -> str:
    """
    Genera una respuesta de fallback cuando OpenAI no est√° disponible
    """
    prompt_lower = prompt.lower()
    
    # Respuestas b√°sicas de fallback
    if any(word in prompt_lower for word in ['hola', 'buenos d√≠as', 'buenas tardes', 'buenas noches', 'saludos']):
        return "¬°Hola! üëã Bienvenido a **Asistente Tienda**. Soy tu asistente virtual y estoy aqu√≠ para ayudarte. ¬øEn qu√© puedo asistirte hoy?"
    
    if any(word in prompt_lower for word in ['productos', 'producto', 'items', 'art√≠culos']):
        return "üõçÔ∏è **Asistente Tienda** tiene una gran variedad de productos de moda disponibles. ¬øHay alg√∫n tipo de producto espec√≠fico que te interese?"
    
    if any(word in prompt_lower for word in ['precio', 'precios', 'costo', 'costos']):
        return "üí∞ **Asistente Tienda** ofrece precios muy competitivos. ¬øHay alg√∫n producto espec√≠fico del que te gustar√≠a conocer el precio?"
    
    if any(word in prompt_lower for word in ['env√≠o', 'env√≠os', 'entrega', 'delivery']):
        return "üöö **Asistente Tienda** ofrece env√≠os a domicilio. ¬øTe gustar√≠a saber m√°s sobre nuestras opciones de env√≠o?"
    
    # Respuesta gen√©rica
    return f"ü§ñ Entiendo tu consulta sobre '{prompt[:50]}...'. Estoy aqu√≠ para ayudarte con informaci√≥n sobre nuestros productos, precios, env√≠os o cualquier otra consulta. ¬øPodr√≠as ser m√°s espec√≠fico sobre lo que necesitas?"

def generate_contextual_response(
    query: str,
    context: Dict[str, Any],
    conversation_history: List[Dict[str, str]] = None
) -> str:
    """
    Genera una respuesta contextualizada usando el sistema RAG avanzado
    """
    if client is None:
        # Usar respuesta inteligente con contexto de la base de datos
        rag_context = ""
        if context.get("document_context"):
            rag_context = context["document_context"]
        elif context.get("product_context"):
            rag_context = context["product_context"]
        
        return generate_smart_response(query, rag_context=rag_context)
    
    # Construir mensajes para el chat
    messages = []
    
    # Mensaje del sistema con personalidad mejorada para productos
    # Mensaje del sistema con personalidad elegante y sofisticada
    system_message = """Eres una consultora de moda experta y elegante para Asistente Tienda, una tienda online de alta calidad. 
    Tu objetivo es ayudar a los clientes de manera sofisticada, profesional y encantadora.
    
    ESTILO DE COMUNICACI√ìN:
    - Tono elegante, sofisticado y amigable
    - Usa emojis de manera sutil y profesional
    - Lenguaje refinado pero accesible
    - Respuestas estructuradas y visualmente atractivas
    - M√°ximo 200 palabras por respuesta
    
    CUANDO MUESTRES PRODUCTOS:
    - Presenta cada producto como una joya √∫nica
    - Destaca caracter√≠sticas especiales y beneficios
    - Usa descripciones evocativas y atractivas
    - NO incluyas enlaces t√©cnicos ni URLs
    - Enf√≥cate en la experiencia del cliente
    - Sugiere combinaciones y estilos
    
    FORMATO ELEGANTE PARA PRODUCTOS:
    ‚ú® [Nombre del producto] - $[precio]
    üíé [Descripci√≥n atractiva y beneficios]
    üõçÔ∏è [Sugerencia de uso o combinaci√≥n]
    
    PERSONALIDAD:
    - Eres una consultora de moda experta y elegante
    - Te emocionas por ayudar a crear looks perfectos
    - Eres detallista pero no abrumadora
    - Mantienes un aire de sofisticaci√≥n y profesionalismo
    - Siempre terminas con una invitaci√≥n amigable para m√°s ayuda
    
    EJEMPLOS DE FRASES ELEGANTES:
    - Perm√≠teme presentarte nuestros tesoros m√°s preciados...
    - Este art√≠culo es simplemente excepcional porque...
    - Imag√≠nate luciendo este hermoso...
    - ¬øTe gustar√≠a conocer m√°s detalles sobre alg√∫n producto en particular?"""
    
    messages.append({"role": "system", "content": system_message})
    
    # Agregar historial de conversaci√≥n
    if conversation_history:
        for msg in conversation_history[-6:]:  # √öltimos 6 mensajes para contexto
            # Manejar tanto objetos como diccionarios
            if isinstance(msg, dict):
                role = "user" if msg.get("sender") == "user" else "assistant"
                content = msg.get("content", "")
            else:
                role = "user" if msg.sender == "user" else "assistant"
                content = msg.content
            messages.append({"role": role, "content": content})
    
    # Construir prompt contextual mejorado
    context_parts = []
    
    if context.get("product_context"):
        context_parts.append(f"INFORMACI√ìN DE PRODUCTOS DISPONIBLES:\n{context['product_context']}")
    
    if context.get("document_context"):
        context_parts.append(f"INFORMACI√ìN ADICIONAL:\n{context['document_context']}")
    
    if context.get("product_mentions"):
        context_parts.append(f"El cliente mencion√≥ estos productos: {', '.join(context['product_mentions'])}")
    
    if context_parts:
        context_prompt = "\n\n".join(context_parts)
        messages.append({"role": "system", "content": f"CONTEXTO ACTUAL:\n{context_prompt}"})
    
    # Agregar la consulta del usuario
    messages.append({"role": "user", "content": query})
    
    # Generar respuesta
    result = advanced_chat_completion(
        messages=messages,
        model="gpt-4o-mini",
        temperature=0.8,  # Aumentar creatividad
        max_tokens=500    # Permitir respuestas m√°s largas para productos
    )
    
    if result["success"]:
        return result["response"]
    else:
        return result["response"]  # Ya incluye mensaje de error amigable

def extract_product_recommendations(response: str) -> List[Dict[str, str]]:
    """
    Extrae recomendaciones de productos de la respuesta del LLM
    """
    # Patr√≥n simple para detectar menciones de productos
    import re
    
    recommendations = []
    # Buscar patrones como "Producto X", "Te recomiendo Y", etc.
    patterns = [
        r'recomiendo\s+([^.!?]+)',
        r'te\s+sugiero\s+([^.!?]+)',
        r'producto[s]?\s+([^.!?]+)',
        r'item[s]?\s+([^.!?]+)'
    ]
    
    for pattern in patterns:
        matches = re.findall(pattern, response.lower())
        for match in matches:
            if len(match.strip()) > 3:
                recommendations.append({
                    "product": match.strip(),
                    "reason": "Recomendado por el asistente"
                })
    
    return recommendations
